<!DOCTYPE html>
<html data-bs-theme="light" lang="en">

<head>
    <meta charset="utf-8">
    <script>
        (function(h,o,t,j,a,r){
            h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
            h._hjSettings={hjid:5064324,hjsv:6};
            a=o.getElementsByTagName('head')[0];
            r=o.createElement('script');r.async=1;
            r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
            a.appendChild(r);
        })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
    </script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>Map Segmentation | Projects</title>
    <link rel="canonical" href="https://evdkv.github.io/proj/map_segmentation">
    <meta property="og:url" content="https://evdkv.github.io/proj/map_segmentation">
    <meta name="twitter:card" content="summary_large_image">
    <meta property="og:type" content="website">
    <meta name="google-site-verification" content="kKYmOHuXKKomaaao17XF9eVI75qv9y08D-nus18byD8">
    <link rel="stylesheet" href="../assets/bootstrap/css/bootstrap.min.css">
    <link rel="stylesheet" href="../assets/css/Articles-Cards-images.css">
    <link rel="stylesheet" href="../assets/css/Navbar-Right-Links-Dark-icons.css">
    <link rel="stylesheet" href="../assets/css/styles.css">
</head>

<body class="text-center">
    <nav class="navbar navbar-expand bg-dark navbar-light py-3" style="height:60px;margin-bottom:0px;">
        <div class="container"><a class="navbar-brand d-flex align-items-center" href="#" style="color:rgb(255, 255, 255);"><span style="color:var(--bs-gray-600);">evdkv</span></a><button data-bs-toggle="collapse" data-bs-target="#navcol-1" class="navbar-toggler" style="background:var(--bs-gray-dark);"><span class="visually-hidden">Toggle navigation</span><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navcol-1">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link active link-secondary" href="/">home</a></li>
                    <li class="nav-item"><a class="nav-link link-secondary" href="../../pub/">publications</a></li>
                    <li class="nav-item"><a class="nav-link link-light" href="../proj/">projects</a></li>
                </ul>
            </div>
        </div>
    </nav>
    <div class="container d-inline-block" style="max-width:827px;"><img class="rounded img-fluid border" src="../assets/img/tumbnail-seg.png" style="width: 804px;margin-top: 60px;position: static;display: block;" width="803" height="577">
        <p style="text-align:left;color:var(--bs-blue);font-size:19px;margin-bottom:-6px;margin-top:22px;">Project</p>
        <h1 class="text-start" style="margin-top:0px;margin-bottom:19px;">Semantic Map Segmentation</h1>
        <div class="d-flex" style="margin-bottom:9px;"><img class="rounded-circle flex-shrink-0 me-3 fit-cover" width="50" height="50" src="../assets/img/profile_pic.jpg">
            <div>
                <p class="fw-bold mb-0">Tolya Evdokimov</p>
                <p class="text-muted mb-0" style="text-align:left;">Author</p>
            </div><img class="rounded-circle flex-shrink-0 me-3 fit-cover" width="50" height="50" src="../assets/img/blank-profile.png" style="margin-left: 15px;">
            <p class="fw-bold mb-0"></p>
            <p class="text-muted mb-0" style="text-align:left;"></p>
            <div>
                <p class="fw-bold mb-0">Sophie Zhao</p>
                <p class="text-muted mb-0" style="text-align:left;">Author</p>
            </div><img class="rounded-circle flex-shrink-0 me-3 fit-cover" width="50" height="50" src="../assets/img/blank-profile.png" style="margin-left: 15px;">
            <div>
                <p class="fw-bold mb-0">Win Aung</p>
                <p class="text-muted mb-0" style="text-align:left;">Author</p>
            </div><img class="rounded-circle flex-shrink-0 me-3 fit-cover" width="50" height="50" src="../assets/img/blank-profile.png" style="margin-left: 15px;">
            <div>
                <p class="fw-bold mb-0">Ginny Zhang</p>
                <p class="text-muted mb-0" style="text-align:left;">Author</p>
            </div>
        </div>
        <p class="text-start text-muted">#supervised_learning #computer_vision #map_segmentation</p>
        <p class="fw-light" style="text-align:left;font-size:19px;">This project is a collaboration for CMSC 395: AI class at the University of Richmond. We thought it might be interesting to look into computer vision and image generation models. So for our final project, we wanted to take several models used for image segmentation and compare them using a publicly available dataset on Kaggle.</p>
        <p><em>The link to the GitHub Repo and the report for the project is at the bottom of the page.</em></p>
        <h3 class="text-start" style="margin-bottom:28px;margin-top:37px;">Problem and Formulation</h3>
        <p class="fw-light" style="text-align:left;font-size:19px;">Map segmentation is an important problem with applications in autopilot systems in self-driving cars, architecture planning, etc. There are many models available out there that tackle map segmentation, and one of the most prominent is U-Net. U-Net consists of an encoder (for feature extraction) and decoder (for up-sampling and image generation). One distinctive feature of U-Net is its skip connections that help recover the information lost in the down-sampling.<br><br>U-Net performs really well, especially on smaller datasets, but there is an alternative architecture - FCN (Fully Connected Network). FCN has several modifications that balance between how many features the model retains in the encoding process through the kernel size and how many features are recovered through skip connections.<br><br>In our project, we explored the difference in performance of three models: U-Net, FCN-8, and FCN-32. We used the map segmentation dataset, implemented the three models using Keras with the TensorFlow back-end. The problem was formulated as a pixel-wise classification task, so we conducted several analyses that examine classification performance.</p>
        <h3 class="text-start" style="margin-bottom:28px;margin-top:37px;">Data Processing</h3>
        <p class="fw-light" style="text-align:left;font-size:19px;">The data was retrieved from a <a href="https://www.kaggle.com/datasets/tpapp157/earth-terrain-height-and-segmentation-map-images/data">publicly available dataset</a> on Kaggle. The dataset contained raw map images and the corresponding segmented maps, where each color corresponded to one of the seven terrain types.</p><img class="img-fluid" src="../assets/img/data-example.png" width="600" style="margin-bottom: 21px;">
        <p class="fw-light" style="text-align:left;font-size:19px;">The raw maps were not modified for the input processing, but the label segmentations required a bit more processing. We retrieved the pixel intensities that corresponded to each terrain type and recoded them to represent class values. We went from a 128x128x3 tensor to 128x128x1, where each value is a class 0-6. The subsequent output form the models is softmax probability distribution so we had to take an argmax and apply the recoding again to get back the generated segmentation. The full data processing pipeline is shown in the figure below.</p><img src="../assets/img/pipeline.png" width="800">
        <h3 class="text-start" style="margin-bottom:28px;margin-top:37px;">Segmentation Models</h3>
        <p class="fw-light" style="text-align:left;font-size:19px;margin-top:40px;margin-bottom:50px;">We chose to compare segmentation performance of three models: U-Net, FCN-8, and FCN-32. U-Net consists of two main parts: encoder and decoder. Encoder down-samples the image and extracts the features, while the decoder up-samples the image and retrieves the features lost during the process of down-sampling using skip connections that connect each decoder component to a corresponding encoder component.<br><br>Both FCN models use large filters to retain features. Additionally, FCN decoders are very shallow which allows for rapid decoding. FCN-8 uses 8x8 kernels which allows it to better extract the features, but it needs two skip connections to obtain the lost features. FCN-32 uses 32x32 kernels and is not using any skip connections. The model architectures with dimensions are shown below.</p><img class="img-fluid" src="../assets/img/segmodels.png" width="800">
        <p class="fw-light" style="text-align:left;font-size:19px;margin-top:40px;margin-bottom:50px;">We hypothesize that U-Net would have superior performance, followed by FCN-8 and FCN-32. Since the dataset contains only 5,000 examples (of which only 4,000 are allocated for training), FCN is likely to start overfitting. We also resized our images from 512x512 to 128x128, which might additionally contribute to FCN overfitting since it has been shown that FCN models perform better on large datasets with higher image resolution (we further explain it in out report).</p>
        <h3 class="text-start" style="margin-bottom:28px;margin-top:37px;">Brief Results</h3>
        <p class="fw-light" style="text-align: left;font-size: 19px;margin-top: 40px;margin-bottom: 0px;">As expected, U-Net had superior performance with 95.11% accuracy on the test set. FCN-8 had classification accuracy of 49.65%, and FCN-32 had 37.86% accuracy on the test set.&nbsp;<br><br>We conducted further accuracy analysis in the paper report for the project, which can be accessed below.</p>
        <figure class="figure"></figure>
        <h3 class="text-start" style="margin-bottom:28px;margin-top:37px;"></h3>
        <p class="fw-light" style="text-align:left;font-size:19px;margin-top:40px;margin-bottom:50px;"></p>
        <figure class="figure">
            <figcaption class="figure-caption"></figcaption>
        </figure>
        <p></p>
        <p class="fw-light" style="text-align:left;font-size:19px;margin-top:40px;margin-bottom:50px;"></p>
        <p class="fw-light" style="text-align:left;font-size:19px;margin-top:0px;margin-bottom:50px;"></p><img class="img-fluid" src="../assets/img/license.png" width="88" height="31" style="margin-right:10px;text-align:left;"><a class="btn btn-dark border rounded" role="button" style="font-size: 13px;margin-right: 10px;" href="https://github.com/evdkv/map-segmentation"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewbox="0 0 16 16" class="bi bi-github" style="font-size:17px;margin-right:10px;"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path></svg>GitHub Repo</a><a class="btn btn-danger border rounded" role="button" style="font-size: 13px;" href="../assets/docs/map_seg_report.pdf">
            <?xml version="1.0" encoding="utf-8"?>
            <svg style="font-size:17px;margin-right:10px;" fill="#000000" width="1em" height="1em" viewBox="0 0 1920 1920" xmlns="http://www.w3.org/2000/svg">
                <g fill-rule="evenodd">
                    <path fill="#FFFFFF" d="M1251.654 0c44.499 0 88.207 18.07 119.718 49.581l329.223 329.224c31.963 31.962 49.581 74.54 49.581 119.717V1920H169V0Zm-66.183 112.941H281.94V1807.06h1355.294V564.706H1185.47V112.94Zm112.94 23.379v315.445h315.445L1298.412 136.32Z"/>
                    <path fill="#FFFFFF" d="M900.497 677.67c26.767 0 50.372 12.65 67.991 37.835 41.901 59.068 38.965 121.976 23.492 206.682-5.308 29.14.113 58.617 16.263 83.125 22.814 34.786 55.68 82.673 87.981 123.219 23.718 29.93 60.198 45.854 97.13 40.885 23.718-3.276 52.292-5.986 81.656-5.986 131.012 0 121.186 46.757 133.045 89.675 6.55 25.976 3.275 48.678-10.165 65.506-16.715 22.701-51.162 34.447-101.534 34.447-55.793 0-74.202-9.487-122.767-24.96-27.445-8.81-55.906-10.617-83.69-3.275-55.453 14.456-146.936 36.48-223.284 46.983-40.772 5.647-77.816 26.654-102.438 60.875-55.454 76.8-106.842 148.518-188.273 148.518-21.007 0-40.32-7.567-56.244-22.701-23.492-23.492-33.544-49.581-28.574-79.85 13.778-92.95 128.075-144.79 196.066-182.625 16.037-8.923 28.687-22.589 36.592-39.53l107.86-233.223c7.68-16.377 10.051-34.56 7.228-52.518-12.537-79.059-31.06-211.99 18.748-272.075 10.955-13.44 26.09-21.007 42.917-21.007Zm20.556 339.953c-43.257 126.607-119.718 264.282-129.996 280.32 92.273-43.37 275.916-65.28 275.916-65.28-92.386-88.998-145.92-215.04-145.92-215.04Z"/>
                </g>
            </svg>Project Report (PDF)</a>
    </div>
    <footer class="text-center bg-dark" style="margin-top:62px;position:sticky;display:block;">
        <div class="container text-white py-4 py-lg-5">
            <p class="text-muted mb-0">© Tolya Evdokimov</p>
        </div>
    </footer>
    <script src="assets/bootstrap/js/bootstrap.min.js"></script>
    <script src="assets/js/bootstrap.min.js"></script>
</body>

</html>